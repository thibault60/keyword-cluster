# app.py
# -*- coding: utf-8 -*-
"""
Amundi â€” Clustering de mots-clÃ©s (â‰¤ 8 catÃ©gories) â€“ Saisie en LISTE (1 par ligne).
Lancez : streamlit run app.py

PrÃ©requis :
  pip install openai>=1.40.0 streamlit>=1.33.0 pandas>=2.1.0 python-dotenv>=1.0.1 openpyxl>=3.1.2 tenacity>=8.2.3

Config :
  - Placez votre clÃ© : OPENAI_API_KEY=sk-...
  - Ou saisissez-la dans la sidebar de lâ€™app.
"""

import os
import math
import json
from pathlib import Path
from typing import List, Dict, Any

import pandas as pd
import streamlit as st
from dotenv import load_dotenv
from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception_type
from openai import OpenAI

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Prompts
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

CATEGORY_DISCOVERY_SYS = """Tu es un analyste SEO senior spÃ©cialisÃ© en asset management.
Ta mission : proposer au plus {max_cat} catÃ©gories thÃ©matiques (noms courts et explicites, en franÃ§ais) pour structurer des mots-clÃ©s relatifs Ã  Amundi.
Objectif : faciliter la priorisation Ã©ditoriale et la visualisation.
Contrainte : 5 Ã  {max_cat} catÃ©gories maximum, pas de doublons, pas de marques concurrentes.
"""

CATEGORY_DISCOVERY_USER = """Voici un Ã©chantillon reprÃ©sentatif de mots-clÃ©s (en {lang}) :
{sample}

Propose UNE LISTE de catÃ©gories (<= {max_cat}). Chaque catÃ©gorie a :
- un champ "name" (3â€“40 caractÃ¨res, concis)
- un champ "description" (1â€“2 phrases max).

Retourne STRICTEMENT un JSON respectant le schÃ©ma fourni.
"""

CATEGORIZATION_SYS = """Tu classes des mots-clÃ©s SEO en EXACTEMENT UNE catÃ©gorie, parmi une liste autorisÃ©e.
Contexte : Asset management / Amundi. Max 8 catÃ©gories.
CritÃ¨res : intention de recherche, univers sÃ©mantique, usage client (institutionnel vs retail), produit (fonds, ETFâ€¦), thÃ¨me (ESG, macro, allocation, Ã©pargne, fiscalitÃ©â€¦).
RÃ©ponds en franÃ§ais.
"""

CATEGORIZATION_USER = """CatÃ©gories AUTORISÃ‰ES (choisis exactement UNE par mot-clÃ©) :
{categories_list}

Mots-clÃ©s Ã  classer (en {lang}) :
{keywords_chunk}

Contraintes :
- Choisis UNIQUEMENT parmi les catÃ©gories autorisÃ©es (ZÃ‰RO catÃ©gorie libre).
- Fourni une confiance [0.0â€“1.0].
- "reason" : justifie en une courte phrase.
Retourne STRICTEMENT le JSON qui respecte le schÃ©ma fourni.
"""

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Utilitaires
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def parse_keyword_list(raw_text: str) -> List[str]:
    """Nettoie et dÃ©duplique une liste collÃ©e (1 mot-clÃ© par ligne)."""
    if not raw_text:
        return []
    lines = [l.strip(" \t,;") for l in raw_text.splitlines()]
    kws = [l for l in lines if l]
    seen = set()
    out = []
    for k in kws:
        knorm = k.strip()
        key = knorm.lower()
        if knorm and key not in seen:
            seen.add(key)
            out.append(knorm)
    return out

def build_summary(df: pd.DataFrame, category_col: str = "category", keyword_col: str = "keyword") -> pd.DataFrame:
    grp = df.groupby(category_col).agg(
        count=(keyword_col, "count"),
        examples=(keyword_col, lambda s: ", ".join(s.head(5)))
    ).reset_index()
    total = grp["count"].sum()
    grp["share"] = (grp["count"] / total).round(4)
    grp = grp.sort_values("count", ascending=False)
    return grp

def export_xlsx(df_detail: pd.DataFrame, out_dir: Path, basename: str = "clustered_keywords") -> str:
    out_dir.mkdir(parents=True, exist_ok=True)
    path = out_dir / f"{basename}_{pd.Timestamp.now().date()}.xlsx"
    with pd.ExcelWriter(path, engine="openpyxl") as writer:
        df_detail.to_excel(writer, index=False, sheet_name="Detailed")
        summary = build_summary(df_detail)
        summary.to_excel(writer, index=False, sheet_name="Summary")
        # Ajustement simple des largeurs
        for sheet_name, df in {"Detailed": df_detail, "Summary": summary}.items():
            ws = writer.sheets[sheet_name]
            for i, col in enumerate(df.columns, 1):
                max_len = max([len(str(x)) for x in [col] + df[col].astype(str).tolist()[:200]])
                ws.column_dimensions[ws.cell(1, i).column_letter].width = min(max(12, max_len + 2), 60)
    return str(path)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# OpenAI client + helpers Structured Outputs
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _client() -> OpenAI:
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        raise RuntimeError("OPENAI_API_KEY manquant. Renseignez-le dans votre environnement ou fichier .env")
    return OpenAI(api_key=api_key)

def _structured_categories_schema(max_cat: int = 8) -> dict:
    return {
        "name": "CategoryProposal",
        "schema": {
            "type": "object",
            "additionalProperties": False,
            "properties": {
                "categories": {
                    "type": "array",
                    "minItems": 3,
                    "maxItems": max_cat,
                    "items": {
                        "type": "object",
                        "additionalProperties": False,
                        "properties": {
                            "name": {"type": "string", "minLength": 3, "maxLength": 40},
                            "description": {"type": "string", "minLength": 5, "maxLength": 240},
                        },
                        "required": ["name"]
                    }
                }
            },
            "required": ["categories"]
        },
        "strict": True
    }

def _structured_batch_schema(allowed: List[str]) -> dict:
    return {
        "name": "BatchCategorization",
        "schema": {
            "type": "object",
            "additionalProperties": False,
            "properties": {
                "items": {
                    "type": "array",
                    "items": {
                        "type": "object",
                        "additionalProperties": False,
                        "properties": {
                            "keyword": {"type": "string"},
                            "category": {"type": "string", "enum": allowed},
                            "confidence": {"type": "number", "minimum": 0.0, "maximum": 1.0},
                            "reason": {"type": "string"}
                        },
                        "required": ["keyword", "category", "confidence"]
                    }
                }
            },
            "required": ["items"]
        },
        "strict": True
    }

def _safe_output_json(resp) -> Any:
    """
    Essaie d'extraire un JSON structurÃ© depuis la rÃ©ponse Responses API.
    PrÃ©fÃ¨re resp.output_json ; fallback sur output_text -> json.loads si nÃ©cessaire.
    """
    try:
        return resp.output_json
    except Exception:
        pass
    try:
        # Certaines versions exposent du texte JSON brut
        txt = getattr(resp, "output_text", None)
        if txt:
            return json.loads(txt)
    except Exception:
        pass
    # Dernier recours : parser le premier bloc de texte s'il existe
    try:
        first = resp.output[0].content[0].text
        return json.loads(first)
    except Exception as e:
        raise RuntimeError(f"Impossible de parser la sortie JSON : {e}")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Appels API (avec retry) â€” CORRIGÃ‰S pour Responses.create(input=[...])
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

@retry(
    reraise=True,
    retry=retry_if_exception_type(Exception),
    stop=stop_after_attempt(3),
    wait=wait_exponential(multiplier=1, min=1, max=8),
)
def propose_categories(sample_keywords: List[str], lang: str = "fr", max_cat: int = 8, model: str = "gpt-4o-mini") -> List[Dict[str, str]]:
    client = _client()
    sys_prompt = CATEGORY_DISCOVERY_SYS.format(max_cat=max_cat)
    user_prompt = CATEGORY_DISCOVERY_USER.format(
        sample="\n".join(f"- {kw}" for kw in sample_keywords[:300]),
        max_cat=max_cat,
        lang=lang
    )
    schema = _structured_categories_schema(max_cat)
    resp = client.responses.create(
        model=model,
        input=[
            {"role": "system", "content": sys_prompt},
            {"role": "user", "content": user_prompt},
        ],
        response_format={"type": "json_schema", "json_schema": schema},
        temperature=0.2,
    )
    data = _safe_output_json(resp)
    return data["categories"]

@retry(
    reraise=True,
    retry=retry_if_exception_type(Exception),
    stop=stop_after_attempt(3),
    wait=wait_exponential(multiplier=1, min=1, max=8),
)
def categorize_batch(keywords: List[str], allowed_categories: List[str], lang: str = "fr", model: str = "gpt-4o-mini") -> List[Dict]:
    client = _client()
    sys_prompt = CATEGORIZATION_SYS
    cat_list = "\n".join(f"- {c}" for c in allowed_categories)
    user_prompt = CATEGORIZATION_USER.format(
        categories_list=cat_list,
        keywords_chunk="\n".join(f"- {k}" for k in keywords),
        lang=lang
    )
    schema = _structured_batch_schema(allowed_categories)
    resp = client.responses.create(
        model=model,
        input=[
            {"role": "system", "content": sys_prompt},
            {"role": "user", "content": user_prompt},
        ],
        response_format={"type": "json_schema", "json_schema": schema},
        temperature=0.1,
    )
    data = _safe_output_json(resp)
    return data["items"]

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Interface Streamlit (LISTE)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def main():
    load_dotenv()
    st.set_page_config(page_title="Amundi - Keyword Clustering (â‰¤8 catÃ©gories)", page_icon="ğŸ“‹", layout="wide")
    st.title("ğŸ“‹ Amundi â€” Clustering de mots-clÃ©s (â‰¤ 8 catÃ©gories) â€” Saisie en liste")
    st.caption("Collez vos mots-clÃ©s (1 par ligne), proposez/Ã©ditez â‰¤ 8 catÃ©gories, export XLSX.")

    with st.sidebar:
        st.header("ğŸ”§ ParamÃ¨tres")
        model = st.selectbox("ModÃ¨le", ["gpt-4o-mini", "gpt-4o-2024-08-06"], index=0)
        lang = st.selectbox("Langue des mots-clÃ©s", ["fr", "en"], index=0)
        batch_size = st.slider("Taille des lots", min_value=25, max_value=250, value=120, step=5)
        st.slider("TempÃ©rature (indicatif)", 0.0, 1.0, 0.2, 0.1, disabled=True)
        st.divider()
        st.write("ğŸ”‘ **OPENAI_API_KEY** :")
        if os.getenv("OPENAI_API_KEY"):
            st.success("ClÃ© dÃ©tectÃ©e via l'environnement / .env")
        else:
            key_input = st.text_input("Renseignez votre clÃ© (optionnel)", type="password")
            if key_input:
                os.environ["OPENAI_API_KEY"] = key_input
                st.success("ClÃ© chargÃ©e en mÃ©moire (session).")

    st.write("## 1) Collez vos mots-clÃ©s (1 par ligne)")
    placeholder = "\n".join([
        "fonds actions europe",
        "amundi research inflation",
        "opcvm durable esg",
        "assurance vie unitÃ©s de compte",
        "obligations court terme",
        "fonds monÃ©taires",
        "allocation multi-actifs",
        "gestion passive etf",
        "scpi rendement",
        "plan Ã©pargne retraite entreprise",
    ])
    raw = st.text_area(
        "Collez ici (copier/coller depuis Excel/Sheets fonctionne) â€” 1 mot-clÃ© par ligne",
        value=placeholder,
        height=240
    )
    keywords_all = parse_keyword_list(raw)
    st.write(f"Total de mots-clÃ©s uniques : **{len(keywords_all)}**")
    if len(keywords_all) == 0:
        st.info("Ajoutez au moins quelques mots-clÃ©s pour continuer.")
        return

    st.write("## 2) DÃ©finition des catÃ©gories (max 8)")
    mode = st.radio("Choix du mode", ["Auto (proposÃ©es par l'IA)", "Manuel (je fournis la liste)"], index=0, horizontal=True)

    categories: List[str] = []
    if mode == "Auto (proposÃ©es par l'IA)":
        sample_size = min(300, max(50, int(len(keywords_all) * 0.2)))
        sample = keywords_all[:sample_size]
        if st.button(f"ğŸ” Proposer des catÃ©gories (Ã©chantillon {sample_size})"):
            try:
                props = propose_categories(sample, lang=lang, max_cat=8, model=model)
                categories = [c["name"] for c in props][:8]
                st.session_state["categories"] = categories
                st.success("CatÃ©gories proposÃ©es : " + ", ".join(categories))
            except Exception as e:
                st.error(f"Erreur proposition catÃ©gories : {e}")
        categories = st.session_state.get("categories", [])
    else:
        manual_default = "MarchÃ©s & Macro, ESG & ISR, Fonds & OPCVM, ETF & Indexation, Allocation & Multi-actifs, Taux & CrÃ©dit, Ã‰pargne & Retraite, FiscalitÃ© & RÃ©glementation"
        manual = st.text_input("Saisissez vos catÃ©gories (sÃ©parÃ©es par des virgules, max 8)", value=manual_default)
        categories = [c.strip() for c in manual.split(",") if c.strip()][:8]

    if categories:
        st.success(f"CatÃ©gories retenues ({len(categories)}) : " + ", ".join(categories))

    st.write("## 3) CatÃ©gorisation")
    if categories and st.button("ğŸš€ Lancer la catÃ©gorisation"):
        results = []
        total = len(keywords_all)
        n_batches = math.ceil(total / batch_size)
        prog = st.progress(0, text="Traitement en coursâ€¦")

        for i in range(n_batches):
            chunk = keywords_all[i * batch_size:(i + 1) * batch_size]
            try:
                items = categorize_batch(chunk, allowed_categories=categories, lang=lang, model=model)
                results.extend(items)
            except Exception as e:
                st.error(f"Erreur lot {i+1}/{n_batches} : {e}")
            prog.progress((i + 1) / n_batches, text=f"Lot {i+1}/{n_batches} traitÃ©")

        if not results:
            st.error("Aucun rÃ©sultat.")
            return

        df_out = pd.DataFrame(results)
        if "reason" not in df_out.columns:
            df_out["reason"] = ""
        df_out = df_out[["keyword", "category", "confidence", "reason"]]

        st.write("### AperÃ§u")
        st.dataframe(df_out.head(20), use_container_width=True)

        out_path = export_xlsx(df_out, Path("exports"))
        with open(out_path, "rb") as f:
            st.download_button(
                "â¬‡ï¸ TÃ©lÃ©charger l'export XLSX",
                data=f.read(),
                file_name=os.path.basename(out_path),
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            )

        st.success(f"Export gÃ©nÃ©rÃ© : {out_path}")
        st.write("### SynthÃ¨se par catÃ©gorie")
        summary = df_out.groupby("category").agg(count=("keyword", "count")).reset_index()
        summary["share"] = (summary["count"] / summary["count"].sum()).round(3)
        st.dataframe(summary.sort_values("count", ascending=False), use_container_width=True)

if __name__ == "__main__":
    main()
