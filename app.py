# app.py
# -*- coding: utf-8 -*-
"""
Amundi â€” Clustering de mots-clÃ©s (â‰¤ 8 catÃ©gories) en un seul fichier.
Lancez : streamlit run app.py

PrÃ©requis :
  pip install openai>=1.40.0 streamlit>=1.33.0 pandas>=2.1.0 python-dotenv>=1.0.1 openpyxl>=3.1.2 tenacity>=8.2.3

Config :
  - Placez votre clÃ© dans l'env : OPENAI_API_KEY=sk-...
  - Ou saisissez-la dans la sidebar de l'app.

Fonctions :
  - Proposer automatiquement 5â€“8 catÃ©gories (Ã©ditables).
  - CatÃ©goriser ~1 000 mots-clÃ©s en EXACTEMENT 1 catÃ©gorie parmi â‰¤ 8.
  - Export XLSX (onglets Detailed + Summary).

Notes :
  - ModÃ¨le par dÃ©faut : gpt-4o-mini.
  - Sorties forÃ§Ã©es via JSON Schema (Responses API -> Structured Outputs).
"""

import os
import math
from pathlib import Path
from typing import List, Dict

import pandas as pd
import streamlit as st
from dotenv import load_dotenv
from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception_type

# OpenAI Python SDK v1.40+ (Responses API)
from openai import OpenAI

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Prompts
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

CATEGORY_DISCOVERY_SYS = """Tu es un analyste SEO senior spÃ©cialisÃ© en asset management.
Ta mission : proposer au plus {max_cat} catÃ©gories thÃ©matiques (noms courts et explicites, en franÃ§ais) pour structurer des mots-clÃ©s relatifs Ã  Amundi.
Objectif : faciliter la priorisation Ã©ditoriale et la visualisation.
Contrainte : 5 Ã  {max_cat} catÃ©gories maximum, pas de doublons, pas de marques concurrentes.
"""

CATEGORY_DISCOVERY_USER = """Voici un Ã©chantillon reprÃ©sentatif de mots-clÃ©s (en {lang}) :
{sample}

Propose UNE LISTE de catÃ©gories (<= {max_cat}). Chaque catÃ©gorie a :
- un champ "name" (3â€“40 caractÃ¨res, concis)
- un champ "description" (1â€“2 phrases max).

Retourne STRICTEMENT un JSON respectant le schÃ©ma fourni.
"""

CATEGORIZATION_SYS = """Tu classes des mots-clÃ©s SEO en EXACTEMENT UNE catÃ©gorie, parmi une liste autorisÃ©e.
Contexte : Asset management / Amundi. Max 8 catÃ©gories.
CritÃ¨res : intention de recherche, univers sÃ©mantique, usage client (institutionnel vs retail), produit (fonds, ETFâ€¦), thÃ¨me (ESG, macro, allocation, Ã©pargne, fiscalitÃ©â€¦).
RÃ©ponds en franÃ§ais.
"""

CATEGORIZATION_USER = """CatÃ©gories AUTORISÃ‰ES (choisis exactement UNE par mot-clÃ©) :
{categories_list}

Mots-clÃ©s Ã  classer (en {lang}) :
{keywords_chunk}

Contraintes :
- Choisis UNIQUEMENT parmi les catÃ©gories autorisÃ©es (ZÃ‰RO catÃ©gorie libre).
- Fourni une confiance [0.0â€“1.0].
- "reason" : justifie en une courte phrase.
Retourne STRICTEMENT le JSON qui respecte le schÃ©ma fourni.
"""

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Utilitaires
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def auto_detect_keyword_column(df: pd.DataFrame) -> str:
    lower_cols = {c.lower(): c for c in df.columns}
    for cand in ["keyword", "keywords", "motcle", "mot_clÃ©", "mot-cle", "mots-clÃ©s", "kw", "query", "requete"]:
        if cand in lower_cols:
            return lower_cols[cand]
    return df.columns[0]

def build_summary(df: pd.DataFrame, category_col: str = "category", keyword_col: str = "keyword") -> pd.DataFrame:
    grp = df.groupby(category_col).agg(
        count=(keyword_col, "count"),
        examples=(keyword_col, lambda s: ", ".join(s.head(5)))
    ).reset_index()
    total = grp["count"].sum()
    grp["share"] = (grp["count"] / total).round(4)
    grp = grp.sort_values("count", ascending=False)
    return grp

def export_xlsx(df_detail: pd.DataFrame, out_dir: Path, basename: str = "clustered_keywords") -> str:
    out_dir.mkdir(parents=True, exist_ok=True)
    path = out_dir / f"{basename}_{pd.Timestamp.now().date()}.xlsx"
    with pd.ExcelWriter(path, engine="openpyxl") as writer:
        df_detail.to_excel(writer, index=False, sheet_name="Detailed")
        summary = build_summary(df_detail)
        summary.to_excel(writer, index=False, sheet_name="Summary")
        # Ajustement trÃ¨s simple des largeurs
        for sheet_name, df in {"Detailed": df_detail, "Summary": summary}.items():
            ws = writer.sheets[sheet_name]
            for i, col in enumerate(df.columns, 1):
                max_len = max([len(str(x)) for x in [col] + df[col].astype(str).tolist()[:200]])
                ws.column_dimensions[ws.cell(1, i).column_letter].width = min(max(12, max_len + 2), 60)
    return str(path)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# OpenAI client + schÃ©mas de sortie structurÃ©e
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _client() -> OpenAI:
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        raise RuntimeError("OPENAI_API_KEY manquant. Renseignez-le dans votre environnement ou fichier .env")
    return OpenAI(api_key=api_key)

def _structured_categories_schema(max_cat: int = 8) -> dict:
    return {
        "name": "CategoryProposal",
        "schema": {
            "type": "object",
            "additionalProperties": False,
            "properties": {
                "categories": {
                    "type": "array",
                    "minItems": 3,
                    "maxItems": max_cat,
                    "items": {
                        "type": "object",
                        "additionalProperties": False,
                        "properties": {
                            "name": {"type": "string", "minLength": 3, "maxLength": 40},
                            "description": {"type": "string", "minLength": 5, "maxLength": 240},
                        },
                        "required": ["name"]
                    }
                }
            },
            "required": ["categories"]
        },
        "strict": True
    }

def _structured_batch_schema(allowed: List[str]) -> dict:
    return {
        "name": "BatchCategorization",
        "schema": {
            "type": "object",
            "additionalProperties": False,
            "properties": {
                "items": {
                    "type": "array",
                    "items": {
                        "type": "object",
                        "additionalProperties": False,
                        "properties": {
                            "keyword": {"type": "string"},
                            "category": {"type": "string", "enum": allowed},
                            "confidence": {"type": "number", "minimum": 0.0, "maximum": 1.0},
                            "reason": {"type": "string"}
                        },
                        "required": ["keyword", "category", "confidence"]
                    }
                }
            },
            "required": ["items"]
        },
        "strict": True
    }

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Appels API (avec retry)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

@retry(
    reraise=True,
    retry=retry_if_exception_type(Exception),
    stop=stop_after_attempt(3),
    wait=wait_exponential(multiplier=1, min=1, max=8),
)
def propose_categories(sample_keywords: List[str], lang: str = "fr", max_cat: int = 8, model: str = "gpt-4o-mini") -> List[Dict[str, str]]:
    client = _client()
    sys = CATEGORY_DISCOVERY_SYS.format(max_cat=max_cat)
    user = CATEGORY_DISCOVERY_USER.format(
        sample="\n".join(f"- {kw}" for kw in sample_keywords[:300]),
        max_cat=max_cat,
        lang=lang
    )
    schema = _structured_categories_schema(max_cat)
    resp = client.responses.create(
        model=model,
        temperature=0.2,
        system=sys,
        input=user,
        response_format={"type": "json_schema", "json_schema": schema},
    )
    data = resp.output_json
    return data["categories"]

@retry(
    reraise=True,
    retry=retry_if_exception_type(Exception),
    stop=stop_after_attempt(3),
    wait=wait_exponential(multiplier=1, min=1, max=8),
)
def categorize_batch(keywords: List[str], allowed_categories: List[str], lang: str = "fr", model: str = "gpt-4o-mini") -> List[Dict]:
    client = _client()
    sys = CATEGORIZATION_SYS
    cat_list = "\n".join(f"- {c}" for c in allowed_categories)
    user = CATEGORIZATION_USER.format(
        categories_list=cat_list,
        keywords_chunk="\n".join(f"- {k}" for k in keywords),
        lang=lang
    )
    schema = _structured_batch_schema(allowed_categories)
    resp = client.responses.create(
        model=model,
        temperature=0.1,
        system=sys,
        input=user,
        response_format={"type": "json_schema", "json_schema": schema},
    )
    data = resp.output_json
    return data["items"]

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Interface Streamlit
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def main():
    load_dotenv()

    st.set_page_config(page_title="Amundi - Keyword Clustering (â‰¤8 catÃ©gories)", page_icon="ğŸ“Š", layout="wide")
    st.title("ğŸ“Š Amundi â€” Clustering de mots-clÃ©s (â‰¤ 8 catÃ©gories)")
    st.caption("Streamlit + OpenAI (Structured Outputs). Export XLSX dÃ©taillÃ© + synthÃ¨se.")

    with st.sidebar:
        st.header("ğŸ”§ ParamÃ¨tres")
        model = st.selectbox("ModÃ¨le", ["gpt-4o-mini", "gpt-4o-2024-08-06"], index=0)
        lang = st.selectbox("Langue des mots-clÃ©s", ["fr", "en"], index=0)
        batch_size = st.slider("Taille des lots", min_value=25, max_value=250, value=120, step=5)
        st.slider("TempÃ©rature (indicatif)", 0.0, 1.0, 0.2, 0.1, disabled=True)  # figÃ© dans le code
        st.divider()
        st.write("ğŸ”‘ **OPENAI_API_KEY**:")
        if os.getenv("OPENAI_API_KEY"):
            st.success("ClÃ© dÃ©tectÃ©e via l'environnement / .env")
        else:
            key_input = st.text_input("Renseignez votre clÃ© (optionnel)", type="password")
            if key_input:
                os.environ["OPENAI_API_KEY"] = key_input
                st.success("ClÃ© chargÃ©e en mÃ©moire (session).")

    st.write("## 1) Import du fichier de mots-clÃ©s")
    upl = st.file_uploader("Chargez un **CSV** ou **XLSX**", type=["csv", "xlsx"])

    if upl is None:
        st.info("Chargez un fichier pour commencer.")
        return

    # Lecture dataset
    if upl.name.lower().endswith(".csv"):
        df = pd.read_csv(upl)
    else:
        df = pd.read_excel(upl)
    if df.empty:
        st.error("Le fichier est vide.")
        return

    kw_col = auto_detect_keyword_column(df)
    st.info(f"Colonne dÃ©tectÃ©e : **{kw_col}**")
    keywords_all = (
        df[kw_col].dropna().astype(str).str.strip()
        .replace("", pd.NA).dropna().drop_duplicates().tolist()
    )
    st.write(f"Total de mots-clÃ©s uniques : **{len(keywords_all)}**")
    st.dataframe(df.head(10))

    st.write("## 2) DÃ©finition des catÃ©gories (max 8)")
    mode = st.radio("Choix du mode", ["Auto (proposÃ©es par l'IA)", "Manuel (je fournis la liste)"], index=0, horizontal=True)

    categories: List[str] = []
    if mode == "Auto (proposÃ©es par l'IA)":
        sample_size = min(300, max(50, int(len(keywords_all) * 0.2)))
        sample = keywords_all[:sample_size]
        if st.button(f"ğŸ” Proposer des catÃ©gories (Ã©chantillon {sample_size})"):
            try:
                props = propose_categories(sample, lang=lang, max_cat=8, model=model)
                categories = [c["name"] for c in props][:8]
                st.session_state["categories"] = categories
                st.success("CatÃ©gories proposÃ©es : " + ", ".join(categories))
            except Exception as e:
                st.error(f"Erreur proposition catÃ©gories : {e}")
        categories = st.session_state.get("categories", [])
    else:
        manual_default = "MarchÃ©s & Macro, ESG & ISR, Fonds & OPCVM, ETF & Indexation, Allocation & Multi-actifs, Taux & CrÃ©dit, Ã‰pargne & Retraite, FiscalitÃ© & RÃ©glementation"
        manual = st.text_input("Saisissez vos catÃ©gories (sÃ©parÃ©es par des virgules, max 8)", value=manual_default)
        categories = [c.strip() for c in manual.split(",") if c.strip()][:8]

    if categories:
        st.success(f"CatÃ©gories retenues ({len(categories)}) : " + ", ".join(categories))

    st.write("## 3) CatÃ©gorisation")
    if categories and st.button("ğŸš€ Lancer la catÃ©gorisation"):
        results = []
        total = len(keywords_all)
        n_batches = math.ceil(total / batch_size)
        prog = st.progress(0, text="Traitement en coursâ€¦")

        for i in range(n_batches):
            chunk = keywords_all[i * batch_size:(i + 1) * batch_size]
            try:
                items = categorize_batch(chunk, allowed_categories=categories, lang=lang, model=model)
                results.extend(items)
            except Exception as e:
                st.error(f"Erreur lot {i+1}/{n_batches} : {e}")
            prog.progress((i + 1) / n_batches, text=f"Lot {i+1}/{n_batches} traitÃ©")

        if not results:
            st.error("Aucun rÃ©sultat.")
            return

        df_out = pd.DataFrame(results)
        if "reason" not in df_out.columns:
            df_out["reason"] = ""
        df_out = df_out[["keyword", "category", "confidence", "reason"]]

        st.write("### AperÃ§u")
        st.dataframe(df_out.head(20), use_container_width=True)

        out_path = export_xlsx(df_out, Path("exports"))
        with open(out_path, "rb") as f:
            st.download_button(
                "â¬‡ï¸ TÃ©lÃ©charger l'export XLSX",
                data=f.read(),
                file_name=os.path.basename(out_path),
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            )

        st.success(f"Export gÃ©nÃ©rÃ© : {out_path}")
        st.write("### SynthÃ¨se par catÃ©gorie")
        summary = df_out.groupby("category").agg(count=("keyword", "count")).reset_index()
        summary["share"] = (summary["count"] / summary["count"].sum()).round(3)
        st.dataframe(summary.sort_values("count", ascending=False), use_container_width=True)

if __name__ == "__main__":
    main()
